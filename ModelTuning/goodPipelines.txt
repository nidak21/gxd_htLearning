# Sep 29, 2017: these are pipeline definitions that are worth comparing
#    since they scored pretty well during tuning experiments.
#  These were compared with compareModels.py
#
  Test  yes       0.64      0.99      0.77       109
  Test  yes       0.60      0.98      0.75       113
### Best Pipeline Parameters:  F1
classifier__C: 1e-05
classifier__loss: 'hinge'
classifier__penalty: 'l2'
vectorizer__max_df: 0.98
vectorizer__min_df: 2
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
LinearSVC(C=1e-05, class_weight='balanced', dual=True, fit_intercept=True,
     intercept_scaling=1, loss='hinge', max_iter=200, multi_class='ovr',
     penalty='l2', random_state=332, tol=0.0001, verbose=0)

scaler:
StandardScaler(copy=True, with_mean=False, with_std=True)

vectorizer:
TfidfVectorizer(analyzer=u'word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.98, max_features=None, min_df=2,
        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None)

  Test  yes       0.69      0.98      0.81       110
### Best Pipeline Parameters:
classifier__alpha: 0.05
classifier__eta0: 0.01
classifier__learning_rate: 'constant'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.98
vectorizer__min_df: 2
vectorizer__ngram_range: (1, 1)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.05, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=999, shuffle=True,
       verbose=0, warm_start=False)

scaler:
MaxAbsScaler(copy=True)

vectorizer:
TfidfVectorizer(analyzer=u'word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.98, max_features=None, min_df=2,
        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None)

  Test  yes       0.64      0.97      0.77       109
### Best Pipeline Parameters:
classifier__alpha: 0.001
classifier__eta0: 0.001
classifier__learning_rate: 'constant'
classifier__loss: 'hinge'
classifier__penalty: 'l2'
vectorizer__max_df: 0.98
vectorizer__min_df: 2
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='hinge', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=815, shuffle=True,
       verbose=0, warm_start=False)

scaler:
MaxAbsScaler(copy=True)

vectorizer:
CountVectorizer(analyzer=u'word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.98, max_features=None, min_df=2,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents='unicode', token_pattern=u'(?i)\\b([a-z_]\\w+)\\b',
        tokenizer=None, vocabulary=None)

  Test  yes       0.71      0.95      0.81       116
### Best Pipeline Parameters:
classifier__C: 0.1
classifier__gamma: 0.1
classifier__kernel: 'sigmoid'
vectorizer__max_df: 0.98
vectorizer__min_df: 2
vectorizer__ngram_range: (1, 3)

### GridSearch Pipeline:
classifier:
SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.1, kernel='sigmoid',
  max_iter=-1, probability=False, random_state=469, shrinking=True,
  tol=0.001, verbose=False)

scaler:
MaxAbsScaler(copy=True)

vectorizer:
TfidfVectorizer(analyzer=u'word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.98, max_features=None, min_df=2,
        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None)

