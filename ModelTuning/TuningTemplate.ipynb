{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: /Users/jak/work/GXD_ht/Data\n",
      "\n",
      "TrainTestSplit random_state = 909\n",
      "All Samples:   1661\tTraining Samples:   1245\tTest Samples:    416\n",
      "Yes count:      563\tYes count:           432\tYes count:       131\n",
      "No  count:     1098\tNo  count:           813\tNo  count:       285\n",
      "Percent Yes:    33%\tPercent Yes:         34%\tPercent Yes:     31%\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.2s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Title: SGDClassifier & TfidfVectorizer & StandardScaler w/ beta=4\n",
      "Fri Sep  1 09:51:39 2017\n",
      "Classifer random_state = 947\n",
      "### Start GridSearch Report\n",
      "GridSearch Pipeline:\n",
      "classifier:\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=947, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "scaler:\n",
      "StandardScaler(copy=True, with_mean=False, with_std=True)\n",
      "\n",
      "vectorizer:\n",
      "TfidfVectorizer(analyzer=u'word', binary=False, decode_error='replace',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=0.98, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents='unicode', sublinear_tf=False,\n",
      "        token_pattern=u'(?u)\\\\b([a-z_]\\\\w+)\\\\b', tokenizer=None,\n",
      "        use_idf=True, vocabulary=None)\n",
      "\n",
      "Best Pipeline Parameters:\n",
      "classifier__alpha: 0.01\n",
      "classifier__eta0: 0.1\n",
      "classifier__learning_rate: 'invscaling'\n",
      "classifier__loss: 'log'\n",
      "classifier__n_iter: 5\n",
      "classifier__penalty: 'l1'\n",
      "vectorizer__max_df: 0.98\n",
      "vectorizer__min_df: 2\n",
      "vectorizer__ngram_range: (1, 3)\n",
      "### End GridSearch Report\n",
      "\n",
      "Vectorizer:   Number of Features: 22623\n",
      "\n",
      "First 10 features: [u'a10', u'a2', u'aa', u'aa4', u'aa4 purified', u'aa4 purified cells', u'abdominal', u'abdominal obesity', u'abdominal obesity overlapped', u'abdominal obesity perturbation']\n",
      "\n",
      "Middle 10 features: [u'labeling hybridization', u'labeling reactions', u'labelled', u'labelled hybridized', u'labelling', u'labelling hybridization', u'laboratory', u'laboratory developed', u'laboratory developed method', u'laboratory directly']\n",
      "\n",
      "Last 10 features: [u'zooepidemicus colony', u'zooepidemicus colony forming', u'zooepidemicus strongly', u'zooepidemicus strongly suggest', u'zurich', u'zurich animals', u'zurich animals acclimatized', u'zygotic', u'zygotic genome', u'zygotic genome activation']\n",
      "\n",
      "Training Set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      1.00      0.99       432\n",
      "\n",
      "avg / total       0.98      1.00      0.99       432\n",
      "\n",
      "F4: 0.997\n",
      "\n",
      "['yes', 'no']\n",
      "[[431   1]\n",
      " [  8 805]]\n",
      "\n",
      "Test Set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.64      0.80      0.71       131\n",
      "\n",
      "avg / total       0.64      0.80      0.71       131\n",
      "\n",
      "F4: 0.789\n",
      "\n",
      "['yes', 'no']\n",
      "[[105  26]\n",
      " [ 60 225]]\n",
      "\n",
      "False positives: 60\n",
      "E-GEOD-528\n",
      "E-GEOD-55340\n",
      "E-GEOD-53156\n",
      "E-ERAD-171\n",
      "E-GEOD-85\n",
      "\n",
      "False negatives: 26\n",
      "E-GEOD-10246\n",
      "E-GEOD-43013\n",
      "E-GEOD-29551\n",
      "E-CBIL-21\n",
      "E-GEOD-55180\n",
      "\n",
      "high weight features\n",
      "### Start top positive features\n",
      "+2.53\tdata livers week\n",
      "+2.53\tlivers week\n",
      "+2.53\tlivers week old\n",
      "+2.43\tdata livers\n",
      "+2.22\tarrays biological\n",
      "+2.08\tarray liver\n",
      "+2.08\tprofiling array liver\n",
      "+1.61\tcontain\n",
      "+1.10\tkit affymetrix\n",
      "+0.96\tusing mas\n",
      "+0.94\tmouse limb bud\n",
      "+0.90\tsummarized\n",
      "+0.89\tmale mice\n",
      "+0.89\tnumber transcripts\n",
      "+0.87\trna ng\n",
      "+0.87\ttotal rna ng\n",
      "+0.86\tarrays\n",
      "+0.85\tsalvage\n",
      "+0.83\twk old mouse\n",
      "+0.80\tmouse gastrocnemius\n",
      "### End top positive features\n",
      "### Start top negative features\n",
      "-0.55\tprimary immune\n",
      "-0.60\tovernight\n",
      "-0.60\tcells\n",
      "-0.60\tkruppel\n",
      "-0.60\tkruppel like\n",
      "-0.62\tgluconeogenesis\n",
      "-0.62\ttissues isolated\n",
      "-0.65\tinsight role\n",
      "-0.68\tdesign liver\n",
      "-0.68\toverall design liver\n",
      "-0.72\tthymic epithelial\n",
      "-0.72\tthymic epithelial cells\n",
      "-0.76\tnull mutants\n",
      "-0.80\taire ko\n",
      "-0.82\tprovide insight role\n",
      "-0.82\tfasted\n",
      "-0.84\tkruppel like factor\n",
      "-0.84\tlike factor\n",
      "-0.85\texpression levels liver\n",
      "-0.85\tlevels liver\n",
      "### End top negative features\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119b73150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "BETA=4\t\t# beta for f-score. >1 weighs recall more than precision\n",
    "\t\t#   when evaluating models\n",
    "TITLE = 'SGDClassifier & TfidfVectorizer & StandardScaler w/ beta=4'\n",
    "#---------------------------------------------------\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('..')\n",
    "import gxd_htLearningLib as gxdLL\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import mglearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# uncomment the next line if we run as a notebook. can try 'auto'\n",
    "#%matplotlib inline\n",
    "#get_ipython().magic(u'matplotlib inline')\t# not sure what this does\n",
    "#---------------------------------------------------\n",
    "ht = gxdLL.GxdHtLearningHelper()\n",
    "\n",
    "# Load dataset and split into training and test set\n",
    "dataset=ht.getTrainingSet()\n",
    "print \"Data Directory: \"  + ht.getDatadir()\n",
    "\n",
    "expIDs = ht.getExpIDs(dataset.filenames)\n",
    "\n",
    "randForSplit = np.random.randint(1000)\t# get random seed 0..1000\n",
    "# randForSplit = 10\t\t\t# uncomment to get fixed seed\n",
    "\n",
    "expIDs_train, expIDs_test, docs_train,   docs_test, y_train,      y_test      = train_test_split(expIDs, dataset.data, dataset.target,\n",
    "\t\t   test_size=0.25, random_state=randForSplit)\n",
    "\n",
    "print \"\\n\" + ht.getTrainTestSplitReport(dataset.target, y_train, y_test,\n",
    "\t\t\t\t\t    random_state=randForSplit)\n",
    "# In[6]:\n",
    "\n",
    "# Run GridSearch on various parameters\n",
    "randForClassifier = np.random.randint(1000)\t# get random seed 0..1000\n",
    "# randForClassifier = 10\t\t\t# uncomment to get fixed seed\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "                     strip_accents='unicode', decode_error='replace',\n",
    "                     token_pattern=u'(?u)\\\\b([a-z_]\\w+)\\\\b',\n",
    "\t\t     stop_words=\"english\") ),\n",
    "    ('scaler'    , StandardScaler(copy=True, with_mean=False, with_std=True) ),\n",
    "    ('classifier', SGDClassifier(verbose=0, eta0=1, class_weight='balanced',\n",
    "    \t\t\trandom_state=randForClassifier) ),\n",
    "    ])\n",
    "parameters={ 'vectorizer__ngram_range':[(1,3)],\n",
    "             'vectorizer__min_df':[2],\n",
    "             'vectorizer__max_df':[.98],\n",
    "             'classifier__eta0':[.1],\n",
    "             'classifier__alpha':[.01],\n",
    "             'classifier__loss':[ 'log' ], #'hinge', 'log','modified_huber'],\n",
    "             'classifier__penalty':['l1'], # ,'elasticnet'\n",
    "             'classifier__n_iter':[5],\n",
    "             'classifier__learning_rate':['invscaling'], # 'constant'\n",
    "            }\n",
    "# Scorer used by GridSearchCV() to rate the pipeline options\n",
    "scorer = ht.makeFscorer(beta=BETA)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, scoring=scorer, cv=5,\n",
    "\t\t    n_jobs=-1, verbose=1)\n",
    "gs.fit( docs_train, y_train )\n",
    "\n",
    "gridSearchTime = time.asctime()\n",
    "\n",
    "bestEstimator   = gs.best_estimator_\n",
    "bestVectorizer  = bestEstimator.named_steps[\"vectorizer\"]\n",
    "bestClassifier  = bestEstimator.named_steps[\"classifier\"]\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "# Print details of the best estimator (pipeline)\n",
    "print \"### Title: \" + TITLE\n",
    "print gridSearchTime\n",
    "print \"Classifer random_state = %d\" % randForClassifier\n",
    "\n",
    "print ht.getGridSearchReport(gs, parameters)\n",
    "print ht.getVectorizerReport(bestVectorizer, nFeatures=10)\n",
    "\n",
    "# Print metrics on predictions for test and training sets\n",
    "y_predicted_test  = bestEstimator.predict(docs_test)\n",
    "y_predicted_train = bestEstimator.predict(docs_train)\n",
    "\n",
    "print ht.getFormatedMetrics(\"Training Set\", y_train, y_predicted_train, BETA) ,\n",
    "print ht.getFormatedMetrics(\"Test Set\",     y_test, y_predicted_test, BETA) ,\n",
    "\n",
    "# print false negatives and positives\n",
    "print ht.getFalsePosNegReport(y_test, y_predicted_test, expIDs_test)\n",
    "\n",
    "print \"high weight features\"\n",
    "print ht.getInterestingFeaturesReport(bestClassifier.coef_,\n",
    "\t\t\t\tbestVectorizer.get_feature_names(), num=20)\n",
    "print\n",
    "\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    bestClassifier.coef_, \n",
    "    bestVectorizer.get_feature_names(), n_top_features=20\n",
    ")\n",
    "plt.title(TITLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
