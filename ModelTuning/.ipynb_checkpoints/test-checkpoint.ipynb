{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: /Users/jak/work/GXD_ht/Data\n",
      "\n",
      "All Samples:   1661\tTraining Samples:   1245\tTest Samples:    416\n",
      "Yes count:      563\tYes count:           423\tYes count:       140\n",
      "No  count:     1098\tNo  count:           822\tNo  count:       276\n",
      "Percent Yes:    33%\tPercent Yes:         33%\tPercent Yes:     33%\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.1s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Title: SGDClassifier & TfidfVectorizer & StandardScaler w/ beta=4\n",
      "Wed Aug 23 10:58:19 2017\n",
      "\n",
      "### Start GridSearch Report\n",
      "GridSearch Pipeline:\n",
      "classifier:\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "scaler:\n",
      "StandardScaler(copy=True, with_mean=False, with_std=True)\n",
      "\n",
      "vectorizer:\n",
      "TfidfVectorizer(analyzer=u'word', binary=False, decode_error='replace',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=0.98, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents='unicode', sublinear_tf=False,\n",
      "        token_pattern=u'(?u)\\\\b([a-z_]\\\\w+)\\\\b', tokenizer=None,\n",
      "        use_idf=True, vocabulary=None)\n",
      "\n",
      "Best Pipeline Parameters:\n",
      "classifier__alpha: 0.01\n",
      "classifier__eta0: 0.1\n",
      "classifier__learning_rate: 'invscaling'\n",
      "classifier__loss: 'log'\n",
      "classifier__n_iter: 5\n",
      "classifier__penalty: 'l1'\n",
      "vectorizer__max_df: 0.98\n",
      "vectorizer__min_df: 2\n",
      "vectorizer__ngram_range: (1, 3)\n",
      "### End GridSearch Report\n",
      "\n",
      "Vectorizer:   Number of Features: 23059\n",
      "\n",
      "First 10 features: [u'a1', u'a10', u'a2', u'aa', u'aa4', u'aa4 purified', u'aa4 purified cells', u'aad', u'abdominal', u'abdominal obesity']\n",
      "\n",
      "Middle 10 features: [u'lamina', u'lamina propria', u'laminin', u'landmarks', u'landscape', u'landscapes', u'landscapes polycomb', u'landscapes polycomb repressive', u'lane', u'lanes']\n",
      "\n",
      "Last 10 features: [u'zone svz', u'zooepidemicus', u'zooepidemicus colony', u'zooepidemicus colony forming', u'zooepidemicus strongly', u'zooepidemicus strongly suggest', u'zurich', u'zygotic', u'zygotic genome', u'zygotic genome activation']\n",
      "\n",
      "Training Set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      1.00      0.99       423\n",
      "\n",
      "avg / total       0.98      1.00      0.99       423\n",
      "\n",
      "F4: 0.999\n",
      "\n",
      "['yes', 'no']\n",
      "[[423   0]\n",
      " [  8 814]]\n",
      "\n",
      "Test Set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.61      0.66      0.63       140\n",
      "\n",
      "avg / total       0.61      0.66      0.63       140\n",
      "\n",
      "F4: 0.654\n",
      "\n",
      "['yes', 'no']\n",
      "[[ 92  48]\n",
      " [ 58 218]]\n",
      "\n",
      "False positives: 58\n",
      "E-GEOD-22094\n",
      "E-GEOD-36095\n",
      "E-TABM-1185\n",
      "E-ERAD-163\n",
      "E-GEOD-72755\n",
      "\n",
      "False negatives: 48\n",
      "E-GEOD-9338\n",
      "E-GEOD-35396\n",
      "E-GEOD-72165\n",
      "E-GEOD-22989\n",
      "E-GEOD-43013\n",
      "\n",
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10f923f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # SGDclassifier & TFIDF VECTORIZER & StandardScaler w/ beta=4\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "BETA=4\n",
    "TITLE = 'SGDClassifier & TfidfVectorizer & StandardScaler w/ beta=4'\n",
    "#---------------------------------------------------\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('..')\n",
    "import gxd_htLearningLib as gxdLL\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import mglearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#from IPython import  get_ipython\n",
    "#get_ipython().magic(u'matplotlib')\n",
    "#get_ipython().magic(u'matplotlib inline')\n",
    "#---------------------------------------------------\n",
    "ht = gxdLL.GxdHtLearningHelper()\n",
    "\n",
    "dataset=ht.getTrainingSet()\n",
    "print \"Data Directory: \"  + ht.getDatadir()\n",
    "\n",
    "expIDs = ht.getExpIDs(dataset.filenames)\n",
    "\n",
    "expIDs_train, expIDs_test, docs_train,   docs_test, y_train,      y_test      = train_test_split(expIDs, dataset.data, dataset.target,\n",
    "                                               test_size=0.25, random_state=10)\n",
    "print \"\\n\" + ht.getTrainTestSplitReport(dataset.target, y_train, y_test) ,\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "# Run GridSearch on various parameters\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "                     strip_accents='unicode', decode_error='replace',\n",
    "                     token_pattern=u'(?u)\\\\b([a-z_]\\w+)\\\\b', stop_words=\"english\") ),\n",
    "    ('scaler'    , StandardScaler(copy=True, with_mean=False, with_std=True) ),\n",
    "    ('classifier', SGDClassifier(verbose=0, eta0=1, class_weight='balanced') ),\n",
    "    ])\n",
    "parameters={ 'vectorizer__ngram_range':[(1,3)],\n",
    "             'vectorizer__min_df':[2],\n",
    "             'vectorizer__max_df':[.98],\n",
    "             'classifier__eta0':[.1],\n",
    "             'classifier__alpha':[.01],\n",
    "             'classifier__loss':[ 'log' ], #'hinge', 'log','modified_huber'],\n",
    "             'classifier__penalty':['l1'], # ,'elasticnet'\n",
    "             'classifier__n_iter':[5],\n",
    "             'classifier__learning_rate':['invscaling'], # 'constant'\n",
    "            }\n",
    "\n",
    "scorer = ht.makeFscorer(beta=BETA)  # used by GridSearchCV() to rate the pipeline options\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, scoring=scorer, cv=5, n_jobs=-1, verbose=1)\n",
    "gs.fit( docs_train, y_train )\n",
    "\n",
    "gridSearchTime = time.asctime()\n",
    "    \n",
    "bestVectorizer  = gs.best_estimator_.named_steps[\"vectorizer\"]\n",
    "bestClassifier  = gs.best_estimator_\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "#import gxd_htLearningLib as gxdLL\n",
    "#ht = gxdLL.GxdHtLearningHelper()\n",
    "\n",
    "print \"### Title: \" + TITLE\n",
    "print gridSearchTime\n",
    "print\n",
    "\n",
    "print ht.getGridSearchReport(gs, parameters)\n",
    "print ht.getVectorizerReport(bestVectorizer, nFeatures=10)\n",
    "\n",
    "# Print metrics on predictions for test and training sets\n",
    "y_predicted_test  = bestClassifier.predict(docs_test)\n",
    "y_predicted_train = bestClassifier.predict(docs_train)\n",
    "\n",
    "print ht.getFormatedMetrics(\"Training Set\", y_train, y_predicted_train, BETA) ,\n",
    "print ht.getFormatedMetrics(\"Test Set\",     y_test, y_predicted_test, BETA) ,\n",
    "\n",
    "# print false negatives and positives\n",
    "print ht.getFalsePosNegReport(y_test, y_predicted_test, expIDs_test)\n",
    "\n",
    "get_ipython().magic(u'matplotlib auto')\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    bestClassifier.named_steps[\"classifier\"].coef_, \n",
    "    bestVectorizer.get_feature_names(), n_top_features=30\n",
    ")\n",
    "plt.title(TITLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
