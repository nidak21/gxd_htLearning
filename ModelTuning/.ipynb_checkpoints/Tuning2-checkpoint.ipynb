{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "BETA=4\t\t# beta for f-score. >1 weighs recall more than precision\n",
    "\t\t#   when evaluating models\n",
    "TITLE = 'SGDClassifier & TfidfVectorizer & StandardScaler w/ beta=4'\n",
    "#---------------------------------------------------\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('..')\n",
    "import gxd_htLearningLib as gxdLL\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import mglearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#%matplotlib inline\t# do this if we run as a notebook. can try 'auto'\n",
    "#get_ipython().magic(u'matplotlib inline')\t# not sure what this does\n",
    "#---------------------------------------------------\n",
    "ht = gxdLL.GxdHtLearningHelper()\n",
    "\n",
    "# Load dataset and split into training and test set\n",
    "dataset=ht.getTrainingSet()\n",
    "print \"Data Directory: \"  + ht.getDatadir()\n",
    "\n",
    "expIDs = ht.getExpIDs(dataset.filenames)\n",
    "\n",
    "expIDs_train, expIDs_test, docs_train,   docs_test, y_train,      y_test      = train_test_split(expIDs, dataset.data, dataset.target,\n",
    "                                               test_size=0.25, random_state=10)\n",
    "print \"\\n\" + ht.getTrainTestSplitReport(dataset.target, y_train, y_test) ,\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# Run GridSearch on various parameters\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "                     strip_accents='unicode', decode_error='replace',\n",
    "                     token_pattern=u'(?u)\\\\b([a-z_]\\w+)\\\\b',\n",
    "\t\t     stop_words=\"english\") ),\n",
    "    ('scaler'    , StandardScaler(copy=True, with_mean=False, with_std=True) ),\n",
    "    ('classifier', SGDClassifier(verbose=0, eta0=1, class_weight='balanced') ),\n",
    "    ])\n",
    "parameters={ 'vectorizer__ngram_range':[(1,3)],\n",
    "             'vectorizer__min_df':[2],\n",
    "             'vectorizer__max_df':[.98],\n",
    "             'classifier__eta0':[.1],\n",
    "             'classifier__alpha':[.01],\n",
    "             'classifier__loss':[ 'log' ], #'hinge', 'log','modified_huber'],\n",
    "             'classifier__penalty':['l1'], # ,'elasticnet'\n",
    "             'classifier__n_iter':[5],\n",
    "             'classifier__learning_rate':['invscaling'], # 'constant'\n",
    "            }\n",
    "# Scorer used by GridSearchCV() to rate the pipeline options\n",
    "scorer = ht.makeFscorer(beta=BETA)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, scoring=scorer, cv=5,\n",
    "\t\t    n_jobs=-1, verbose=1)\n",
    "gs.fit( docs_train, y_train )\n",
    "\n",
    "gridSearchTime = time.asctime()\n",
    "\n",
    "bestEstimator   = gs.best_estimator_\n",
    "bestVectorizer  = bestEstimator.named_steps[\"vectorizer\"]\n",
    "bestClassifier  = bestEstimator.named_steps[\"classifier\"]\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "# Print details of the best estimator (pipeline)\n",
    "print \"### Title: \" + TITLE\n",
    "print gridSearchTime\n",
    "print\n",
    "\n",
    "print type(bestClassifier.coef_)\n",
    "print bestClassifier.coef_.shape\n",
    "print type(bestVectorizer.get_feature_names())\n",
    "print len(bestVectorizer.get_feature_names())\n",
    "\n",
    "print ht.getGridSearchReport(gs, parameters)\n",
    "print ht.getVectorizerReport(bestVectorizer, nFeatures=10)\n",
    "\n",
    "# Print metrics on predictions for test and training sets\n",
    "y_predicted_test  = bestEstimator.predict(docs_test)\n",
    "y_predicted_train = bestEstimator.predict(docs_train)\n",
    "\n",
    "print ht.getFormatedMetrics(\"Training Set\", y_train, y_predicted_train, BETA) ,\n",
    "print ht.getFormatedMetrics(\"Test Set\",     y_test, y_predicted_test, BETA) ,\n",
    "\n",
    "# print false negatives and positives\n",
    "print ht.getFalsePosNegReport(y_test, y_predicted_test, expIDs_test)\n",
    "\n",
    "print \"high weight features\"\n",
    "hPos, hNeg =  ht.getInterestingFeatures(bestClassifier.coef_,\n",
    "\t\t\t\tbestVectorizer.get_feature_names())\n",
    "print hPos\n",
    "print\n",
    "print hNeg\n",
    "\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    bestClassifier.coef_, \n",
    "    bestVectorizer.get_feature_names(), n_top_features=30\n",
    ")\n",
    "plt.title(TITLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
