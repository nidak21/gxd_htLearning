{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import mglearn \n",
    "from IPython.display import display \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Perceptron \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.datasets import load_files\n",
    "%matplotlib \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading experiment title/description from data folder\n",
    "dataset=load_files('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784\n",
      "595\n",
      "1784\n",
      "595\n",
      "Feature matrix:\n",
      "<1784x79774 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 177753 stored elements in Compressed Sparse Row format>\n",
      "<type 'list'>\n",
      "79774\n",
      "[u'00', u'00 00', u'00 20', u'00 800', u'00 ad', u'00 day', u'00 final', u'00 night', u'000', u'000 50']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#splitting 'yes'/'no' files ramdomly into training and test set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "docs_train, docs_test, y_train, y_test =train_test_split(dataset.data, dataset.target,test_size=0.25, train_size=0.75,random_state=10)\n",
    "print len(docs_train)\n",
    "print len(docs_test)\n",
    "print len(y_train)\n",
    "print len(y_test)\n",
    "\n",
    "vect = TfidfVectorizer(strip_accents='unicode', analyzer='word',ngram_range=(1,2),stop_words=\"english\").fit(docs_train)\n",
    "X_train = vect.transform(docs_train)\n",
    "print(\"Feature matrix:\\n{}\".format(repr(X_train)))\n",
    "\n",
    "print type(vect.get_feature_names())\n",
    "print len(vect.get_feature_names())\n",
    "print vect.get_feature_names()[:10]\n",
    "print vect.vocabulary_['00 night']\n",
    "\n",
    "#feature_names=np.array(lr_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,make_scorer,fbeta_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mglearn\n",
    "\n",
    "\n",
    "\n",
    "clf=Pipeline([('vect', TfidfVectorizer(strip_accents='unicode', analyzer='word',ngram_range=(1,2),stop_words=\"english\")),\n",
    "             ('logreg',LogisticRegression(C=100)),\n",
    "])\n",
    "\n",
    "parameters={'vect__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "            'vect__max_df':[.7,.8,.9],\n",
    "            #'vect__min_df':[.1,.2,.3],\n",
    "            'logreg__C':[1,10,100]\n",
    "}\n",
    "\n",
    "#Initializing scorer method \n",
    "MYBETA=4\n",
    "f_scorer=make_scorer(fbeta_score,beta=MYBETA,pos_label=1)\n",
    "\n",
    "#Running GridSearch\n",
    "lr_gs_clf=GridSearchCV(clf,parameters,n_jobs=-1,scoring=f_scorer)\n",
    "lr_gs_clf=lr_gs_clf.fit(docs_train,y_train)\n",
    "lr_trainedCLF=lr_gs_clf.best_estimator_\n",
    "lr_vectorizer=lr_gs_clf.best_estimator_.named_steps[\"vect\"]\n",
    "\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s:%r\"%(param_name,lr_gs_clf.best_params_[param_name]))\n",
    "print(\"\\n\")\n",
    "\n",
    "#feature_names found by the vectorizer\n",
    "print type(lr_vectorizer.get_feature_names())\n",
    "print len(lr_vectorizer.get_feature_names())\n",
    "print lr_vectorizer.get_feature_names()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_predicted=lr_trainedCLF.predict(docs_test)\n",
    "lr_y_train_predicted=lr_trainedCLF.predict(docs_train)\n",
    "lr_vectorizer=lr_gs_clf.best_estimator_.named_steps[\"vect\"]\n",
    "print lr_vectorizer.vocabulary_['00 00 night']\n",
    "print type(lr_vectorizer.get_feature_names())\n",
    "print len(lr_vectorizer.get_feature_names())\n",
    "print lr_vectorizer.get_feature_names()[:10]\n",
    "feature_names=np.array(lr_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing Classification Report for Test Set \n",
    "print(\"Test Set Classification Report & Confusion Matrix: \\n\")\n",
    "print(metrics.classification_report(y_test, lr_y_predicted,target_names=['yes','no'],labels=[1,0], ))\n",
    "print \"F1: %5.3f\"%f1_score(y_test,lr_y_predicted,pos_label=1)\n",
    "\n",
    "#Printing Confusion Matrix for Test Set \n",
    "cm=metrics.confusion_matrix( lr_y_predicted, y_test, labels=[1,0])\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Printing Classification Report for Training Set \n",
    "print(\"Training Set Classification Report & Confusion Matrix: \\n\")\n",
    "print(metrics.classification_report(y_train, lr_y_train_predicted,target_names=['yes','no'],labels=[1,0], ))\n",
    "\n",
    "\n",
    "#Printing Confusion Matrix for Training Set \n",
    "cm=metrics.confusion_matrix( lr_y_train_predicted, y_train, labels=[1,0])\n",
    "print(cm)\n",
    "\n",
    "\n",
    "#lr_trainedCLF.predict_proba(docs_train)\n",
    "print lr_trainedCLF.named_steps[\"logreg\"].coef_.shape\n",
    "print lr_trainedCLF.named_steps[\"logreg\"].coef_\n",
    "print\n",
    "print feature_names.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "   lr_trainedCLF.named_steps[\"logreg\"].coef_, \n",
    "    feature_names, n_top_features=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score,make_scorer,fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scorer method\n",
    "MYBETA=4\n",
    "f_scorer=make_scorer(fbeta_score,beta=MYBETA,pos_label=1)\n",
    "\n",
    "#Running Grid Search\n",
    "clf=Pipeline([('lsvect', TfidfVectorizer(strip_accents='unicode', analyzer='word',stop_words=\"english\", ngram_range=(1,2),max_df=.7,min_df=.1)),\n",
    "             ('linSVC', LinearSVC()),\n",
    "])\n",
    "\n",
    "parameters={'lsvect__ngram_range':[(1,1),(1,2)],\n",
    "            'lsvect__max_df':[.7,.8,.9],\n",
    "            'lsvect__min_df':[.1,.2,.3],\n",
    "            'linSVC__C':[1,10,100,100]\n",
    "}\n",
    "\n",
    "ls_grids_clf=GridSearchCV(clf,parameters,n_jobs=-1,scoring=f_scorer)\n",
    "ls_grids_clf=ls_grids_clf.fit(docs_train,y_train)\n",
    "ls_vectorizer=ls_grids_clf.best_estimator_.named_steps[\"lsvect\"]\n",
    "ls_feature_names=np.array(ls_vectorizer.get_feature_names())\n",
    "ls_trainedCLF=ls_grids_clf.best_estimator_\n",
    "\n",
    "ls_y_predicted=ls_trainedCLF.predict(docs_test)\n",
    "ls_y_predict=ls_trainedCLF.predict(docs_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing Classification Report for Test Set \n",
    "print(\"Test Set Classification Report & Confusion Matrix: \\n\")\n",
    "print(metrics.classification_report(y_test, ls_y_predicted,target_names=['yes','no'],labels=[1,0], ))\n",
    "print \"F1: %5.3f\"%f1_score(y_test,ls_y_predicted,pos_label=1)\n",
    "\n",
    "#Printing Confusion Matrix for Test Set \n",
    "cm=metrics.confusion_matrix(  ls_y_predicted, y_test, labels=[1,0])\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "   ls_trainedCLF.named_steps[\"linSVC\"].coef_, \n",
    "   ls_feature_names, n_top_features=10\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,make_scorer,fbeta_score\n",
    "\n",
    "#Initializing Scorer Method \n",
    "MYBETA=2\n",
    "f_scorer=make_scorer(fbeta_score,beta=MYBETA,pos_label=1)\n",
    "\n",
    "#Running GridSearch \n",
    "clf=Pipeline([ \n",
    "               ('vect', TfidfVectorizer(strip_accents='unicode', analyzer='word', stop_words=\"english\")), \n",
    "               ('Prcpt', Perceptron()),\n",
    "])\n",
    "\n",
    "parameters={  'vect__ngram_range':[(1,1),(1,2)],\n",
    "              'vect__max_df':[.7,.8,.9],\n",
    "              'vect__min_df':[.1,.2,.3],\n",
    "              'Prcpt__alpha':[.1,.01,.001,.0001] \n",
    "           }\n",
    "\n",
    "prcpt_gs_clf=GridSearchCV(clf,parameters,n_jobs=-1,scoring=f_scorer)\n",
    "prcpt_gs_clf=prcpt_gs_clf.fit(docs_train,y_train)\n",
    "prcpt_vectorizer=prcpt_gs_clf.best_estimator_.named_steps[\"vect\"]\n",
    "prcpt_feature_names=np.array(prcpt_vectorizer.get_feature_names())\n",
    "print (\"Best params: \\n\")\n",
    "print(prcpt_gs_clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prcpt_trainedCLF=prcpt_gs_clf.best_estimator_\n",
    "prcpt_y_predicted=prcpt_trainedCLF.predict(docs_test)\n",
    "prcpt_y_predict=prcpt_trainedCLF.predict(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Printing Classification Report & Confusion Matrix for Test Set \n",
    "print(\"Test set: \\n\")\n",
    "print(metrics.classification_report(y_test, prcpt_y_predicted, target_names=['yes','no'], labels=[1,0]))\n",
    "cm=metrics.confusion_matrix( prcpt_y_predicted, y_test, labels=[1,0])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "   prcpt_trainedCLF.named_steps[\"Prcpt\"].coef_, \n",
    "    prcpt_feature_names, n_top_features=20\n",
    ")\n",
    "plt.title(\"Perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "\n",
    "dataset=load_files('data')\n",
    "docs_train, docs_test, y_train, y_test =train_test_split(dataset.data, dataset.target,test_size=0.25, train_size=0.75,random_state=10)\n",
    "\n",
    "clf=Pipeline([\n",
    "             ('vect', TfidfVectorizer(strip_accents='unicode', analyzer='word',stop_words=\"english\", ngram_range=(1,2),max_df=.7,min_df=.1)\n",
    "             )\n",
    "             #('deci', DecisionTreeClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "X_train_counts=clf.fit(docs_train)\n",
    "tree=DecisionTreeClassifier(max_depth=6000, random_state=0)\n",
    "tree.fit(X_train_counts, y_train)\n",
    "print (\"Accuracy on training set: {:3f}\".format(tree.score(X_train_counts,y_train)))\n",
    "print (\"Accuracy on test set: {:3f}\".format(tree.score(X_test,y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
