{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/jak/work/GXD_ht/Data\n",
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import gxd_htLearningLib as ht\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import mglearn\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics # confusion_matrix?\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jak/work/GXD_ht/Data/yes/E-GEOD-27836'\n",
      " '/Users/jak/work/GXD_ht/Data/no/E-GEOD-28228'\n",
      " '/Users/jak/work/GXD_ht/Data/no/E-GEOD-31822'\n",
      " '/Users/jak/work/GXD_ht/Data/no/E-GEOD-44359']\n"
     ]
    }
   ],
   "source": [
    "# Load experiments\n",
    "\n",
    "dataset=ht.getTrainingSet()\n",
    "print dataset.filenames[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E-GEOD-27836', 'E-GEOD-28228', 'E-GEOD-31822', 'E-GEOD-44359']\n"
     ]
    }
   ],
   "source": [
    "# Get Experiment IDs from file names\n",
    "\n",
    "exp_IDs = ht.getExpIDs(dataset.filenames)\n",
    "print exp_IDs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Experiments: 1661\n",
      "Yes count: 563\n",
      "No count:  1098\n",
      "\n",
      "Number of Training Experiments: 1245\n",
      "Yes count: 423\n",
      "No count:  822\n",
      "\n",
      "Number of Test Experiments: 416\n",
      "Yes count: 140\n",
      "No count:  276\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test sets\n",
    "\n",
    "exp_IDs_train, exp_IDs_test, \\\n",
    "docs_train,    docs_test, \\\n",
    "y_train,       y_test      = train_test_split(exp_IDs, dataset.data, dataset.target,\n",
    "                                               test_size=0.25, random_state=10)\n",
    "\n",
    "print \"Total Number of Experiments: %d\" % len(dataset.filenames)\n",
    "print \"Yes count: %d\" % (dataset.target.tolist()).count(1)\n",
    "print \"No count:  %d\" % (dataset.target.tolist()).count(0)\n",
    "print\n",
    "print \"Number of Training Experiments: %d\" % len(y_train)\n",
    "print \"Yes count: %d\" % (y_train.tolist()).count(1)\n",
    "print \"No count:  %d\" % (y_train.tolist()).count(0)\n",
    "print \n",
    "print \"Number of Test Experiments: %d\" % len(y_test)\n",
    "print \"Yes count: %d\" % (y_test.tolist()).count(1)\n",
    "print \"No count:  %d\" % (y_test.tolist()).count(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF VECTORIZER w/ beta=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "-- Epoch 1\n",
      "Norm: 0.92, NNZs: 4374, Bias: -0.000136, T: 830, Avg. loss: 0.533953\n",
      "-- Epoch 1\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.97, NNZs: 4360, Bias: -0.000208, T: 1660, Avg. loss: 0.372158\n",
      "Norm: 1.05, NNZs: 4429, Bias: -0.000138, T: 830, Avg. loss: 0.561962\n",
      "Total training time: 0.03 seconds.\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "Norm: 1.01, NNZs: 4327, Bias: -0.000232, T: 2490, Avg. loss: 0.302564\n",
      "Norm: 1.10, NNZs: 4379, Bias: -0.000211, T: 1660, Avg. loss: 0.388392\n",
      "Total training time: 0.06 seconds.\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.13, NNZs: 4352, Bias: -0.000238, T: 2490, Avg. loss: 0.313622\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.16, NNZs: 4321, Bias: -0.000253, T: 3320, Avg. loss: 0.270544\n",
      "-- Epoch 4\n",
      "Norm: 1.04, NNZs: 4284, Bias: -0.000250, T: 3320, Avg. loss: 0.262843\n",
      "-- Epoch 1\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 1.04, NNZs: 4305, Bias: -0.000046, T: 830, Avg. loss: 0.569971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.06, NNZs: 4275, Bias: -0.000266, T: 4150, Avg. loss: 0.236491\n",
      "Total training time: 0.11 seconds.\n",
      "Norm: 1.09, NNZs: 4269, Bias: -0.000109, T: 1660, Avg. loss: 0.395351\n",
      "-- Epoch 5\n",
      "Norm: 1.18, NNZs: 4289, Bias: -0.000267, T: 4150, Avg. loss: 0.242167\n",
      "Total training time: 0.04 seconds.\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.12, NNZs: 4254, Bias: -0.000133, T: 2490, Avg. loss: 0.319901\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.15, NNZs: 4240, Bias: -0.000148, T: 3320, Avg. loss: 0.276354\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.17, NNZs: 4230, Bias: -0.000162, T: 4150, Avg. loss: 0.247412\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.39, NNZs: 10917, Bias: -0.000133, T: 830, Avg. loss: 0.597708\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.42, NNZs: 10751, Bias: -0.000193, T: 1660, Avg. loss: 0.355676\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.44, NNZs: 10664, Bias: -0.000216, T: 2490, Avg. loss: 0.261108\n",
      "-- Epoch 1\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.45, NNZs: 10605, Bias: -0.000230, T: 3320, Avg. loss: 0.211265\n",
      "Norm: 1.51, NNZs: 10431, Bias: -0.000135, T: 830, Avg. loss: 0.620627\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.53, NNZs: 10310, Bias: -0.000197, T: 1660, Avg. loss: 0.372669\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.54, NNZs: 10164, Bias: -0.000222, T: 2490, Avg. loss: 0.274546\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.46, NNZs: 10524, Bias: -0.000242, T: 4150, Avg. loss: 0.180267\n",
      "Total training time: 0.12 seconds.\n",
      "Norm: 1.55, NNZs: 10133, Bias: -0.000235, T: 3320, Avg. loss: 0.221912\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.56, NNZs: 10090, Bias: -0.000245, T: 4150, Avg. loss: 0.188921\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.50, NNZs: 10375, Bias: -0.000045, T: 830, Avg. loss: 0.636672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.52, NNZs: 10376, Bias: -0.000101, T: 1660, Avg. loss: 0.384549\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.53, NNZs: 10145, Bias: -0.000123, T: 2490, Avg. loss: 0.285564\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.55, NNZs: 10028, Bias: -0.000136, T: 3320, Avg. loss: 0.231647\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.56, NNZs: 9962, Bias: -0.000146, T: 4150, Avg. loss: 0.197355\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 7.61, NNZs: 3966, Bias: -0.001131, T: 830, Avg. loss: 1.462938\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.61, NNZs: 3945, Bias: -0.001177, T: 1660, Avg. loss: 0.838277\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "Norm: 7.61, NNZs: 3893, Bias: -0.001260, T: 2490, Avg. loss: 0.591562\n",
      "Norm: 11.19, NNZs: 3921, Bias: -0.001233, T: 830, Avg. loss: 2.103136\n",
      "Total training time: 0.03 seconds.\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.19, NNZs: 3875, Bias: -0.001454, T: 1660, Avg. loss: 1.184011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 4\n",
      "Norm: 7.61, NNZs: 3825, Bias: -0.001314, T: 3320, Avg. loss: 0.458866\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.18, NNZs: 3820, Bias: -0.001568, T: 2490, Avg. loss: 0.827108\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.61, NNZs: 3776, Bias: -0.001337, T: 4150, Avg. loss: 0.374142\n",
      "Total training time: 0.07 seconds.\n",
      "Norm: 11.18, NNZs: 3781, Bias: -0.001618, T: 3320, Avg. loss: 0.639499\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.18, NNZs: 3745, Bias: -0.001651, T: 4150, Avg. loss: 0.522523\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.54, NNZs: 14640, Bias: -0.000130, T: 830, Avg. loss: 0.737233\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 1\n",
      "Norm: 1.66, NNZs: 13634, Bias: -0.000129, T: 830, Avg. loss: 0.696492\n",
      "Total training time: 0.02 seconds.\n",
      "Norm: 1.56, NNZs: 14513, Bias: -0.000189, T: 1660, Avg. loss: 0.440650\n",
      "-- Epoch 2\n",
      "Total training time: 0.05 seconds.\n",
      "Norm: 1.67, NNZs: 13468, Bias: -0.000187, T: 1660, Avg. loss: 0.418419\n",
      "-- Epoch 3\n",
      "Norm: 1.57, NNZs: 14346, Bias: -0.000209, T: 2490, Avg. loss: 0.313760\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.69, NNZs: 13280, Bias: -0.000213, T: 2490, Avg. loss: 0.302834\n",
      "Norm: 1.58, NNZs: 14204, Bias: -0.000222, T: 3320, Avg. loss: 0.247867\n",
      "Total training time: 0.07 seconds.\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 4\n",
      "Norm: 1.69, NNZs: 13111, Bias: -0.000226, T: 3320, Avg. loss: 0.240991\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 14109, Bias: -0.000233, T: 4150, Avg. loss: 0.207372\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 1.70, NNZs: 13021, Bias: -0.000237, T: 4150, Avg. loss: 0.202628\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 11.11, NNZs: 3806, Bias: -0.000705, T: 830, Avg. loss: 2.041211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.11, NNZs: 3768, Bias: -0.001053, T: 1660, Avg. loss: 1.114431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.11, NNZs: 3707, Bias: -0.001143, T: 2490, Avg. loss: 0.762941\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11.11, NNZs: 3653, Bias: -0.001188, T: 3320, Avg. loss: 0.579036\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.11, NNZs: 3615, Bias: -0.001208, T: 4150, Avg. loss: 0.465177\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.52, NNZs: 13989, Bias: -0.000074, T: 830, Avg. loss: 0.641628\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.54, NNZs: 13746, Bias: -0.000129, T: 1660, Avg. loss: 0.370388\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.55, NNZs: 13574, Bias: -0.000149, T: 2490, Avg. loss: 0.267484\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.56, NNZs: 13488, Bias: -0.000162, T: 3320, Avg. loss: 0.212366\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 1.57, NNZs: 13400, Bias: -0.000171, T: 4150, Avg. loss: 0.178252\n",
      "Norm: 15.17, NNZs: 8296, Bias: -0.000131, T: 830, Avg. loss: 3.071192\n",
      "Total training time: 0.01 seconds.\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.24, NNZs: 8643, Bias: -0.000165, T: 1660, Avg. loss: 1.623884\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.24, NNZs: 8568, Bias: -0.000189, T: 2490, Avg. loss: 1.092263\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.24, NNZs: 8324, Bias: -0.000211, T: 3320, Avg. loss: 0.820908\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.24, NNZs: 8216, Bias: -0.000219, T: 4150, Avg. loss: 0.657020\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.45, NNZs: 8303, Bias: -0.001125, T: 830, Avg. loss: 3.676931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.45, NNZs: 8337, Bias: -0.001228, T: 1660, Avg. loss: 2.127201\n",
      "-- Epoch 1\n",
      "Norm: 15.43, NNZs: 8252, Bias: -0.000602, T: 830, Avg. loss: 3.576671\n",
      "Total training time: 0.06 seconds.\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.43, NNZs: 8271, Bias: -0.000710, T: 1660, Avg. loss: 2.016726\n",
      "-- Epoch 3\n",
      "Norm: 17.44, NNZs: 8245, Bias: -0.001318, T: 2490, Avg. loss: 1.508335\n",
      "Total training time: 0.09 seconds.\n",
      "Total training time: 0.03 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 3\n",
      "-- Epoch 4\n",
      "Norm: 15.42, NNZs: 8180, Bias: -0.000764, T: 2490, Avg. loss: 1.408797\n",
      "Norm: 17.43, NNZs: 8161, Bias: -0.001353, T: 3320, Avg. loss: 1.179162\n",
      "Total training time: 0.05 seconds.\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Norm: 15.41, NNZs: 8083, Bias: -0.000796, T: 3320, Avg. loss: 1.086071\n",
      "Norm: 17.42, NNZs: 8098, Bias: -0.001373, T: 4150, Avg. loss: 0.970160\n",
      "Total training time: 0.13 seconds.\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.41, NNZs: 7964, Bias: -0.000824, T: 4150, Avg. loss: 0.880248\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.80, NNZs: 3101, Bias: -0.000147, T: 830, Avg. loss: 0.568583\n",
      "Total training time: 0.02 seconds.\n",
      "Norm: 0.87, NNZs: 2860, Bias: -0.000224, T: 1660, Avg. loss: 0.451505\n",
      "-- Epoch 2\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.92, NNZs: 2661, Bias: -0.000271, T: 2490, Avg. loss: 0.398577\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.96, NNZs: 2526, Bias: -0.000305, T: 3320, Avg. loss: 0.367169\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.00, NNZs: 2419, Bias: -0.000331, T: 4150, Avg. loss: 0.345840\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.80, NNZs: 11692, Bias: -0.000886, T: 830, Avg. loss: 5.405270\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.66, NNZs: 11623, Bias: -0.000916, T: 1660, Avg. loss: 3.636588\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.58, NNZs: 11541, Bias: -0.000975, T: 2490, Avg. loss: 2.779900\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.53, NNZs: 11515, Bias: -0.000986, T: 3320, Avg. loss: 2.264449\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.51, NNZs: 11342, Bias: -0.001018, T: 4150, Avg. loss: 1.910485\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.88, NNZs: 3017, Bias: -0.000143, T: 830, Avg. loss: 0.554608\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.94, NNZs: 2785, Bias: -0.000221, T: 1660, Avg. loss: 0.432329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.99, NNZs: 2606, Bias: -0.000269, T: 2490, Avg. loss: 0.380425\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.03, NNZs: 2494, Bias: -0.000303, T: 3320, Avg. loss: 0.350414\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.06, NNZs: 2396, Bias: -0.000329, T: 4150, Avg. loss: 0.330161\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.93, NNZs: 2981, Bias: -0.000123, T: 830, Avg. loss: 0.563730\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.00, NNZs: 2722, Bias: -0.000187, T: 1660, Avg. loss: 0.435167\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.04, NNZs: 2539, Bias: -0.000225, T: 2490, Avg. loss: 0.381075\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.08, NNZs: 2402, Bias: -0.000250, T: 3320, Avg. loss: 0.349730\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.11, NNZs: 2316, Bias: -0.000274, T: 4150, Avg. loss: 0.329126\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.24, NNZs: 10748, Bias: -0.001061, T: 830, Avg. loss: 3.667406\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.29, NNZs: 10564, Bias: -0.001187, T: 1660, Avg. loss: 2.187494\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.29, NNZs: 10583, Bias: -0.001231, T: 2490, Avg. loss: 1.532557\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.28, NNZs: 10419, Bias: -0.001261, T: 3320, Avg. loss: 1.188464\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.29, NNZs: 10470, Bias: -0.001265, T: 4150, Avg. loss: 0.970523\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.33, NNZs: 7575, Bias: -0.000113, T: 830, Avg. loss: 0.575173\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.37, NNZs: 6364, Bias: -0.000207, T: 1660, Avg. loss: 0.392424\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.40, NNZs: 5642, Bias: -0.000260, T: 2490, Avg. loss: 0.326633\n",
      "-- Epoch 1\n",
      "Norm: 1.43, NNZs: 7086, Bias: -0.000147, T: 830, Avg. loss: 0.570332\n",
      "Total training time: 0.04 seconds.\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 5145, Bias: -0.000302, T: 3320, Avg. loss: 0.293480\n",
      "-- Epoch 2\n",
      "Norm: 1.47, NNZs: 5794, Bias: -0.000247, T: 1660, Avg. loss: 0.386622\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.50, NNZs: 5220, Bias: -0.000300, T: 2490, Avg. loss: 0.320871\n",
      "Total training time: 0.03 seconds.\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.46, NNZs: 4619, Bias: -0.000336, T: 4150, Avg. loss: 0.273423\n",
      "-- Epoch 4\n",
      "Norm: 1.53, NNZs: 4755, Bias: -0.000338, T: 3320, Avg. loss: 0.287078\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 1.55, NNZs: 4404, Bias: -0.000372, T: 4150, Avg. loss: 0.266820\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.32, NNZs: 10222, Bias: -0.000423, T: 830, Avg. loss: 4.550339\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.33, NNZs: 10365, Bias: -0.000607, T: 1660, Avg. loss: 2.709510\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.31, NNZs: 10267, Bias: -0.000670, T: 2490, Avg. loss: 1.923419\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.30, NNZs: 10123, Bias: -0.000701, T: 3320, Avg. loss: 1.491522\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.29, NNZs: 10045, Bias: -0.000716, T: 4150, Avg. loss: 1.216785\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.42, NNZs: 7044, Bias: -0.000144, T: 830, Avg. loss: 0.611289\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.46, NNZs: 5770, Bias: -0.000227, T: 1660, Avg. loss: 0.408902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.50, NNZs: 5217, Bias: -0.000271, T: 2490, Avg. loss: 0.335641\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.52, NNZs: 4753, Bias: -0.000300, T: 3320, Avg. loss: 0.297858\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.54, NNZs: 4401, Bias: -0.000327, T: 4150, Avg. loss: 0.275029\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.33, NNZs: 2716, Bias: -0.001293, T: 830, Avg. loss: 1.772259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 10.36, NNZs: 2156, Bias: -0.001679, T: 1660, Avg. loss: 0.982172\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.38, NNZs: 1823, Bias: -0.001881, T: 2490, Avg. loss: 0.684902\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.40, NNZs: 1622, Bias: -0.002027, T: 3320, Avg. loss: 0.531835\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.41, NNZs: 1479, Bias: -0.002110, T: 4150, Avg. loss: 0.440036\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 9.55, NNZs: 2496, Bias: -0.001288, T: 830, Avg. loss: 1.522648\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 1\n",
      "Norm: 9.58, NNZs: 2021, Bias: -0.001683, T: 1660, Avg. loss: 0.861610\n",
      "Norm: 8.54, NNZs: 2488, Bias: -0.000636, T: 830, Avg. loss: 1.600138\n",
      "Total training time: 0.02 seconds.\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.55, NNZs: 1900, Bias: -0.000994, T: 1660, Avg. loss: 0.968784\n",
      "-- Epoch 3\n",
      "Total training time: 0.04 seconds.\n",
      "Norm: 9.61, NNZs: 1710, Bias: -0.001834, T: 2490, Avg. loss: 0.606724\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 4\n",
      "Norm: 8.55, NNZs: 1590, Bias: -0.001190, T: 2490, Avg. loss: 0.727078\n",
      "Norm: 9.63, NNZs: 1506, Bias: -0.001947, T: 3320, Avg. loss: 0.475035\n",
      "Total training time: 0.08 seconds.\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Norm: 8.56, NNZs: 1360, Bias: -0.001340, T: 3320, Avg. loss: 0.602432\n",
      "Norm: 9.65, NNZs: 1341, Bias: -0.002004, T: 4150, Avg. loss: 0.397206\n",
      "Total training time: 0.10 seconds.\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.57, NNZs: 1184, Bias: -0.001481, T: 4150, Avg. loss: 0.526723\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.70, NNZs: 10312, Bias: -0.000142, T: 830, Avg. loss: 0.702424\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.74, NNZs: 8292, Bias: -0.000225, T: 1660, Avg. loss: 0.456425\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Norm: 1.47, NNZs: 8918, Bias: -0.000177, T: 830, Avg. loss: 0.609779\n",
      "Norm: 1.76, NNZs: 7288, Bias: -0.000273, T: 2490, Avg. loss: 0.364694\n",
      "Total training time: 0.02 seconds.\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "Norm: 1.51, NNZs: 7285, Bias: -0.000261, T: 1660, Avg. loss: 0.403209\n",
      "Norm: 1.79, NNZs: 6535, Bias: -0.000313, T: 3320, Avg. loss: 0.318150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0.04 seconds.\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "Norm: 1.81, NNZs: 6173, Bias: -0.000344, T: 4150, Avg. loss: 0.289804\n",
      "Norm: 1.54, NNZs: 6626, Bias: -0.000311, T: 2490, Avg. loss: 0.329948\n",
      "Total training time: 0.16 seconds.\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.56, NNZs: 6241, Bias: -0.000349, T: 3320, Avg. loss: 0.292691\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.58, NNZs: 5808, Bias: -0.000379, T: 4150, Avg. loss: 0.270034\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1.64, NNZs: 9109, Bias: -0.000154, T: 830, Avg. loss: 0.674257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.67, NNZs: 7344, Bias: -0.000236, T: 1660, Avg. loss: 0.432499\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.70, NNZs: 6686, Bias: -0.000280, T: 2490, Avg. loss: 0.346279\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.72, NNZs: 6049, Bias: -0.000310, T: 3320, Avg. loss: 0.302731\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.74, NNZs: 5438, Bias: -0.000336, T: 4150, Avg. loss: 0.276897\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.44, NNZs: 6085, Bias: -0.001868, T: 830, Avg. loss: 3.363627\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.47, NNZs: 4941, Bias: -0.002234, T: 1660, Avg. loss: 1.909477\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.49, NNZs: 4162, Bias: -0.002362, T: 2490, Avg. loss: 1.328783\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.50, NNZs: 3655, Bias: -0.002511, T: 3320, Avg. loss: 1.023557\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.51, NNZs: 3250, Bias: -0.002665, T: 4150, Avg. loss: 0.839665\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.73, NNZs: 5918, Bias: -0.001064, T: 830, Avg. loss: 2.458817\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.78, NNZs: 4590, Bias: -0.001591, T: 1660, Avg. loss: 1.323807\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.79, NNZs: 3869, Bias: -0.001702, T: 2490, Avg. loss: 0.901265\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.80, NNZs: 3302, Bias: -0.001914, T: 3320, Avg. loss: 0.689832\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.82, NNZs: 2826, Bias: -0.002049, T: 4150, Avg. loss: 0.564368\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.34, NNZs: 6297, Bias: -0.000664, T: 830, Avg. loss: 3.937275\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.30, NNZs: 4989, Bias: -0.000995, T: 1660, Avg. loss: 2.524191\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.27, NNZs: 4143, Bias: -0.001201, T: 2490, Avg. loss: 1.923248\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.25, NNZs: 3538, Bias: -0.001357, T: 3320, Avg. loss: 1.583676\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.24, NNZs: 3121, Bias: -0.001447, T: 4150, Avg. loss: 1.361329\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.15, NNZs: 9541, Bias: -0.001314, T: 830, Avg. loss: 5.014139\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.19, NNZs: 7828, Bias: -0.001493, T: 1660, Avg. loss: 3.002187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.20, NNZs: 6510, Bias: -0.001782, T: 2490, Avg. loss: 2.094697\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.21, NNZs: 5599, Bias: -0.002008, T: 3320, Avg. loss: 1.612081\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.22, NNZs: 4923, Bias: -0.002202, T: 4150, Avg. loss: 1.303874\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.66, NNZs: 8158, Bias: -0.000555, T: 830, Avg. loss: 3.804360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.72, NNZs: 6047, Bias: -0.001251, T: 1660, Avg. loss: 2.209667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.72, NNZs: 4890, Bias: -0.001494, T: 2490, Avg. loss: 1.565809\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.74, NNZs: 4254, Bias: -0.001699, T: 3320, Avg. loss: 1.209233\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.76, NNZs: 3744, Bias: -0.001830, T: 4150, Avg. loss: 0.987130\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.67, NNZs: 8365, Bias: -0.000716, T: 830, Avg. loss: 5.288840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.56, NNZs: 6519, Bias: -0.001058, T: 1660, Avg. loss: 3.552133\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.50, NNZs: 5435, Bias: -0.001242, T: 2490, Avg. loss: 2.803346\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.46, NNZs: 4625, Bias: -0.001431, T: 3320, Avg. loss: 2.372040\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.43, NNZs: 4080, Bias: -0.001524, T: 4150, Avg. loss: 2.081089\n",
      "Total training time: 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.99, NNZs: 3446, Bias: -0.000124, T: 1245, Avg. loss: 0.557296\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.06, NNZs: 3028, Bias: -0.000211, T: 2490, Avg. loss: 0.440592\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.11, NNZs: 2753, Bias: -0.000264, T: 3735, Avg. loss: 0.390791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.16, NNZs: 2590, Bias: -0.000298, T: 4980, Avg. loss: 0.361785\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.19, NNZs: 2412, Bias: -0.000330, T: 6225, Avg. loss: 0.342672\n",
      "Total training time: 0.01 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer=u'word', binary=False, decode_error='replace',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_id...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=2, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'classifier__n_iter': [5], 'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)], 'classifier__alpha': [0.001, 0.01], 'classifier__learning_rate': ['invscaling'], 'vectorizer__min_df': [2], 'classifier__eta0': [0.01, 0.1], 'classifier__loss': ['log'], 'vectorizer__max_df': [0.98], 'classifier__penalty': ['l1']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(fbeta_score, beta=4, pos_label=1), verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run GridSearch on various parameters\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "                     strip_accents='unicode', decode_error='replace',\n",
    "                     token_pattern=u'(?u)\\\\b([a-z_]\\w+)\\\\b', stop_words=\"english\") ),\n",
    "    ('scaler'    , StandardScaler(copy=True, with_mean=False, with_std=True) ),\n",
    "    ('classifier', SGDClassifier(verbose=2, eta0=1, class_weight='balanced') ),\n",
    "    ])\n",
    "parameters={ 'vectorizer__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "             'vectorizer__min_df':[2],\n",
    "             'vectorizer__max_df':[.98],\n",
    "             'classifier__eta0':[.01,.1],\n",
    "             'classifier__alpha':[.001,.01],\n",
    "             'classifier__loss':[ 'log' ], #'hinge', 'log','modified_huber'],\n",
    "             'classifier__penalty':['l1'], # ,'elasticnet'\n",
    "             'classifier__n_iter':[5],\n",
    "             'classifier__learning_rate':['invscaling'], # 'constant'\n",
    "            }\n",
    "BETA=4\n",
    "scorer = ht.makeFscorer(beta=BETA)  # used by GridSearchCV() to rate the pipeline options\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, scoring=scorer, n_jobs=-1, verbose=1)\n",
    "gs.fit( docs_train, y_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Pipeline Parameters\n",
      "classifier__alpha:0.01\n",
      "classifier__eta0:0.01\n",
      "classifier__learning_rate:'invscaling'\n",
      "classifier__loss:'log'\n",
      "classifier__n_iter:5\n",
      "classifier__penalty:'l1'\n",
      "vectorizer__max_df:0.98\n",
      "vectorizer__min_df:2\n",
      "vectorizer__ngram_range:(1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get best vectorizer and classifier, print best tuning parameters\n",
    "\n",
    "best_vect = gs.best_estimator_.named_steps[\"vectorizer\"]\n",
    "best_clf  = gs.best_estimator_\n",
    "\n",
    "print (\"Best Pipeline Parameters\")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s:%r\"% (param_name, gs.best_params_[param_name]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 5725\n",
      "\n",
      "First 10 features: [u'a1', u'a10', u'a2', u'aa', u'aa4', u'aad', u'abdominal', u'aberrant', u'aberrations', u'ability']\n",
      "\n",
      "Middle 10 features: [u'lactogenic', u'lacz', u'lad', u'lag', u'lamin', u'lamina', u'laminin', u'landmarks', u'landscape', u'landscapes']\n",
      "\n",
      "Last 10 features: [u'zero', u'zfp36', u'zinc', u'zipper', u'zn', u'zona', u'zone', u'zooepidemicus', u'zurich', u'zygotic']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out some features as a sanity check for the vectorizer\n",
    "\n",
    "print ht.getVectorizerReport(best_vect, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Test Set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.78      0.83      0.80       140\n",
      "         no       0.91      0.88      0.90       276\n",
      "\n",
      "avg / total       0.87      0.86      0.86       416\n",
      "\n",
      "F4: 0.825\n",
      "\n",
      "['yes', 'no']\n",
      "[[116  24]\n",
      " [ 33 243]]\n",
      "\n",
      "\n",
      "For the Training Set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.96      0.99      0.98       423\n",
      "         no       1.00      0.98      0.99       822\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1245\n",
      "\n",
      "F4: 0.989\n",
      "\n",
      "['yes', 'no']\n",
      "[[419   4]\n",
      " [ 16 806]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print metrics on predictions for test and training sets\n",
    "\n",
    "y_predicted_test  = best_clf.predict(docs_test)\n",
    "y_predicted_train = best_clf.predict(docs_train)\n",
    "\n",
    "print \"For the Test Set\"\n",
    "print ht.getFormatedMetrics(y_test, y_predicted_test, BETA)\n",
    "\n",
    "print \"For the Training Set\"\n",
    "print ht.getFormatedMetrics(y_train, y_predicted_train, BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'falselyReported' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a6688b14e351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mfalselyReported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_names_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'falselyReported' is not defined"
     ]
    }
   ],
   "source": [
    "print falselyReported(y_test, y_test_predicted, file_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "    trainedCLF.named_steps[\"classifier\"].coef_, \n",
    "    feature_names, n_top_features=30\n",
    ")\n",
    "plt.title(\"SGDClassifier with TfidfVectorizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
