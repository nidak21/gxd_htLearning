Sample Split 0
Pipeline 0:   F1: 0.835   F4: 0.891   Precision: 0.78   Recall: 0.90
Pipeline 1:   F1: 0.834   F4: 0.891   Precision: 0.78   Recall: 0.90
Pipeline 2:   F1: 0.818   F4: 0.865   Precision: 0.77   Recall: 0.87
Pipeline 3:   F1: 0.813   F4: 0.855   Precision: 0.77   Recall: 0.86
Pipeline 4:   F1: 0.813   F4: 0.855   Precision: 0.77   Recall: 0.86
Pipeline 5:   F1: 0.833   F4: 0.858   Precision: 0.81   Recall: 0.86
Pipeline 6:   F1: 0.825   F4: 0.849   Precision: 0.80   Recall: 0.85
Sample Split 1
Pipeline 0:   F1: 0.828   F4: 0.870   Precision: 0.78   Recall: 0.88
Pipeline 1:   F1: 0.829   F4: 0.873   Precision: 0.78   Recall: 0.88
Pipeline 2:   F1: 0.813   F4: 0.853   Precision: 0.77   Recall: 0.86
Pipeline 3:   F1: 0.792   F4: 0.803   Precision: 0.78   Recall: 0.80
Pipeline 4:   F1: 0.792   F4: 0.803   Precision: 0.78   Recall: 0.80
Pipeline 5:   F1: 0.822   F4: 0.830   Precision: 0.81   Recall: 0.83
Pipeline 6:   F1: 0.833   F4: 0.846   Precision: 0.82   Recall: 0.85
Sample Split 2
Pipeline 0:   F1: 0.862   F4: 0.914   Precision: 0.81   Recall: 0.92
Pipeline 1:   F1: 0.863   F4: 0.912   Precision: 0.81   Recall: 0.92
Pipeline 2:   F1: 0.845   F4: 0.883   Precision: 0.81   Recall: 0.89
Pipeline 3:   F1: 0.843   F4: 0.889   Precision: 0.80   Recall: 0.90
Pipeline 4:   F1: 0.843   F4: 0.889   Precision: 0.80   Recall: 0.90
Pipeline 5:   F1: 0.861   F4: 0.893   Precision: 0.83   Recall: 0.90
Pipeline 6:   F1: 0.857   F4: 0.881   Precision: 0.83   Recall: 0.88
Sample Split 3
Pipeline 0:   F1: 0.848   F4: 0.906   Precision: 0.79   Recall: 0.91
Pipeline 1:   F1: 0.848   F4: 0.905   Precision: 0.79   Recall: 0.91
Pipeline 2:   F1: 0.824   F4: 0.882   Precision: 0.77   Recall: 0.89
Pipeline 3:   F1: 0.828   F4: 0.879   Precision: 0.78   Recall: 0.89
Pipeline 4:   F1: 0.828   F4: 0.879   Precision: 0.78   Recall: 0.89
Pipeline 5:   F1: 0.856   F4: 0.889   Precision: 0.82   Recall: 0.89
Pipeline 6:   F1: 0.856   F4: 0.889   Precision: 0.82   Recall: 0.89
Sample Split 4
Pipeline 0:   F1: 0.820   F4: 0.857   Precision: 0.78   Recall: 0.86
Pipeline 1:   F1: 0.822   F4: 0.859   Precision: 0.78   Recall: 0.86
Pipeline 2:   F1: 0.812   F4: 0.836   Precision: 0.79   Recall: 0.84
Pipeline 3:   F1: 0.799   F4: 0.817   Precision: 0.78   Recall: 0.82
Pipeline 4:   F1: 0.799   F4: 0.817   Precision: 0.78   Recall: 0.82
Pipeline 5:   F1: 0.822   F4: 0.834   Precision: 0.81   Recall: 0.84
Pipeline 6:   F1: 0.814   F4: 0.828   Precision: 0.80   Recall: 0.83
Sample Split 5
Pipeline 0:   F1: 0.854   F4: 0.912   Precision: 0.80   Recall: 0.92
Pipeline 1:   F1: 0.854   F4: 0.912   Precision: 0.80   Recall: 0.92
Pipeline 2:   F1: 0.828   F4: 0.884   Precision: 0.77   Recall: 0.89
Pipeline 3:   F1: 0.827   F4: 0.876   Precision: 0.78   Recall: 0.88
Pipeline 4:   F1: 0.827   F4: 0.876   Precision: 0.78   Recall: 0.88
Pipeline 5:   F1: 0.846   F4: 0.883   Precision: 0.81   Recall: 0.89
Pipeline 6:   F1: 0.850   F4: 0.881   Precision: 0.82   Recall: 0.88
Sample Split 6
Pipeline 0:   F1: 0.829   F4: 0.876   Precision: 0.78   Recall: 0.88
Pipeline 1:   F1: 0.829   F4: 0.876   Precision: 0.78   Recall: 0.88
Pipeline 2:   F1: 0.810   F4: 0.855   Precision: 0.76   Recall: 0.86
Pipeline 3:   F1: 0.806   F4: 0.842   Precision: 0.77   Recall: 0.85
Pipeline 4:   F1: 0.806   F4: 0.842   Precision: 0.77   Recall: 0.85
Pipeline 5:   F1: 0.821   F4: 0.834   Precision: 0.81   Recall: 0.84
Pipeline 6:   F1: 0.831   F4: 0.848   Precision: 0.81   Recall: 0.85
Sample Split 7
Pipeline 0:   F1: 0.834   F4: 0.883   Precision: 0.78   Recall: 0.89
Pipeline 1:   F1: 0.833   F4: 0.882   Precision: 0.78   Recall: 0.89
Pipeline 2:   F1: 0.817   F4: 0.863   Precision: 0.77   Recall: 0.87
Pipeline 3:   F1: 0.809   F4: 0.865   Precision: 0.75   Recall: 0.87
Pipeline 4:   F1: 0.809   F4: 0.865   Precision: 0.75   Recall: 0.87
Pipeline 5:   F1: 0.834   F4: 0.862   Precision: 0.80   Recall: 0.87
Pipeline 6:   F1: 0.828   F4: 0.854   Precision: 0.80   Recall: 0.86
Sample Split 8
Pipeline 0:   F1: 0.826   F4: 0.890   Precision: 0.76   Recall: 0.90
Pipeline 1:   F1: 0.828   F4: 0.890   Precision: 0.77   Recall: 0.90
Pipeline 2:   F1: 0.809   F4: 0.861   Precision: 0.76   Recall: 0.87
Pipeline 3:   F1: 0.815   F4: 0.871   Precision: 0.76   Recall: 0.88
Pipeline 4:   F1: 0.815   F4: 0.871   Precision: 0.76   Recall: 0.88
Pipeline 5:   F1: 0.831   F4: 0.859   Precision: 0.80   Recall: 0.86
Pipeline 6:   F1: 0.838   F4: 0.862   Precision: 0.81   Recall: 0.86
Sample Split 9
Pipeline 0:   F1: 0.823   F4: 0.872   Precision: 0.77   Recall: 0.88
Pipeline 1:   F1: 0.819   F4: 0.870   Precision: 0.77   Recall: 0.88
Pipeline 2:   F1: 0.819   F4: 0.876   Precision: 0.76   Recall: 0.88
Pipeline 3:   F1: 0.808   F4: 0.851   Precision: 0.76   Recall: 0.86
Pipeline 4:   F1: 0.808   F4: 0.851   Precision: 0.76   Recall: 0.86
Pipeline 5:   F1: 0.828   F4: 0.848   Precision: 0.81   Recall: 0.85
Pipeline 6:   F1: 0.824   F4: 0.852   Precision: 0.80   Recall: 0.86

Average. 0:   F1: 0.836   F4: 0.887   Precision: 0.78   Recall: 0.89
Average. 1:   F1: 0.836   F4: 0.887   Precision: 0.79   Recall: 0.89
Average. 2:   F1: 0.819   F4: 0.866   Precision: 0.77   Recall: 0.87
Average. 3:   F1: 0.814   F4: 0.855   Precision: 0.77   Recall: 0.86
Average. 4:   F1: 0.814   F4: 0.855   Precision: 0.77   Recall: 0.86
Average. 5:   F1: 0.835   F4: 0.859   Precision: 0.81   Recall: 0.86
Average. 6:   F1: 0.836   F4: 0.859   Precision: 0.81   Recall: 0.86

Training data: ../data/training/mar2018bal/
2018/04/09-15-40-38

Pipeline 0 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.8, max_features=None, min_df=0.01,
        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', StandardScaler(copy=True, with_mean=False, with_std=True))
('classifier', LinearSVC(C=0.0001, class_weight='balanced', dual=True, fit_intercept=True,
     intercept_scaling=1, loss='hinge', max_iter=200, multi_class='ovr',
     penalty='l2', random_state=None, tol=0.0001, verbose=0))

Pipeline 1 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.7, max_features=None, min_df=0.01,
        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', StandardScaler(copy=True, with_mean=False, with_std=True))
('classifier', LinearSVC(C=0.0001, class_weight='balanced', dual=True, fit_intercept=True,
     intercept_scaling=1, loss='hinge', max_iter=200, multi_class='ovr',
     penalty='l2', random_state=None, tol=0.0001, verbose=0))

Pipeline 2 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.8, max_features=None, min_df=0.01,
        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', MaxAbsScaler(copy=True))
('classifier', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.1, kernel='sigmoid',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))

Pipeline 3 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.7, max_features=None, min_df=0.01,
        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', StandardScaler(copy=True, with_mean=False, with_std=True))
('classifier', LogisticRegression(C=1e-06, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))

Pipeline 4 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.7, max_features=None, min_df=0.01,
        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', StandardScaler(copy=True, with_mean=False, with_std=True))
('classifier', LogisticRegression(C=1e-06, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))

Pipeline 5 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.8, max_features=None, min_df=0.01,
        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', StandardScaler(copy=True, with_mean=False, with_std=True))
('classifier', SGDClassifier(alpha=1e-08, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False))

Pipeline 6 -------------
('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.8, max_features=None, min_df=0.01,
        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents='unicode', sublinear_tf=False,
        token_pattern=u'(?i)\\b([a-z_]\\w+)\\b', tokenizer=None,
        use_idf=True, vocabulary=None))
('scaler', StandardScaler(copy=True, with_mean=False, with_std=True))
('classifier', SGDClassifier(alpha=1e-09, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False))
